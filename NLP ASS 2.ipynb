{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5pA7OMF0yMz+ONNNIG8m/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c05d92a4","executionInfo":{"status":"ok","timestamp":1767867280562,"user_tz":-330,"elapsed":8599,"user":{"displayName":"DANGETI KARTHIK RAM","userId":"02974783247328024150"}},"outputId":"2622b422-afcf-4d1e-e93e-2b08e8567b33"},"source":["import nltk\n","import spacy\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","# Download necessary NLTK data\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","print(\"NLTK and spaCy modules imported and NLTK data downloaded.\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["NLTK and spaCy modules imported and NLTK data downloaded.\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"markdown","metadata":{"id":"76cbd236"},"source":["**Reasoning**:\n","The previous code failed because the NLTK 'punkt_tab' resource was not downloaded, leading to a `LookupError` during sentence tokenization. I will add `nltk.download('punkt_tab')` to ensure all necessary NLTK data is available before performing tokenization, fixing the immediate issue in this code block.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e008cd8","executionInfo":{"status":"ok","timestamp":1767867439491,"user_tz":-330,"elapsed":1488,"user":{"displayName":"DANGETI KARTHIK RAM","userId":"02974783247328024150"}},"outputId":"97faff26-3b5a-4e09-e710-62bd5308a8b5"},"source":["import spacy\n","\n","# 1. Initialize the spaCy English model\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Ensure 'punkt_tab' is downloaded for NLTK sentence tokenization\n","nltk.download('punkt_tab')\n","\n","# 2. Process the medical_text using the loaded spaCy model\n","doc = nlp(medical_text)\n","\n","print(\"--- NLTK Tokenization ---\")\n","# 3. Tokenize medical_text into sentences using NLTK\n","nltk_sentences = sent_tokenize(medical_text)\n","print(\"NLTK Sentences:\", nltk_sentences)\n","\n","# 4. Tokenize medical_text into words using NLTK\n","nltk_words = word_tokenize(medical_text)\n","print(\"NLTK Words:\", nltk_words)\n","\n","print(\"\\n--- spaCy Tokenization ---\")\n","# 5. Extract sentences from the spaCy doc object\n","spacy_sentences = [sent.text for sent in doc.sents]\n","print(\"spaCy Sentences:\", spacy_sentences)\n","\n","# 6. Extract words (tokens) from the spaCy doc object\n","spacy_words = [token.text for token in doc]\n","print(\"spaCy Words:\", spacy_words)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["--- NLTK Tokenization ---\n","NLTK Sentences: ['The patient presented with persistent headaches and a history of chronic migraines, requiring urgent neurological consultation for further assessment and treatment plans.']\n","NLTK Words: ['The', 'patient', 'presented', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'requiring', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plans', '.']\n","\n","--- spaCy Tokenization ---\n","spaCy Sentences: ['The patient presented with persistent headaches and a history of chronic migraines, requiring urgent neurological consultation for further assessment and treatment plans.']\n","spaCy Words: ['The', 'patient', 'presented', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'requiring', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plans', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a714804b","executionInfo":{"status":"ok","timestamp":1767867472742,"user_tz":-330,"elapsed":1669,"user":{"displayName":"DANGETI KARTHIK RAM","userId":"02974783247328024150"}},"outputId":"74b797a6-45b2-472f-bbeb-a6a9d0365051"},"source":["import spacy\n","\n","# 1. Initialize the spaCy English model\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Ensure 'punkt_tab' is downloaded for NLTK sentence tokenization\n","nltk.download('punkt_tab')\n","\n","# 2. Process the medical_text using the loaded spaCy model\n","doc = nlp(medical_text)\n","\n","print(\"--- NLTK Tokenization ---\")\n","# 3. Tokenize medical_text into sentences using NLTK\n","nltk_sentences = sent_tokenize(medical_text);\n","print(\"NLTK Sentences:\", nltk_sentences)\n","\n","# 4. Tokenize medical_text into words using NLTK\n","nltk_words = word_tokenize(medical_text)\n","print(\"NLTK Words:\", nltk_words)\n","\n","print(\"\\n--- spaCy Tokenization ---\")\n","# 5. Extract sentences from the spaCy doc object\n","spacy_sentences = [sent.text for sent in doc.sents]\n","print(\"spaCy Sentences:\", spacy_sentences)\n","\n","# 6. Extract words (tokens) from the spaCy doc object\n","spacy_words = [token.text for token in doc]\n","print(\"spaCy Words:\", spacy_words)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["--- NLTK Tokenization ---\n","NLTK Sentences: ['The patient presented with persistent headaches and a history of chronic migraines, requiring urgent neurological consultation for further assessment and treatment plans.']\n","NLTK Words: ['The', 'patient', 'presented', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'requiring', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plans', '.']\n","\n","--- spaCy Tokenization ---\n","spaCy Sentences: ['The patient presented with persistent headaches and a history of chronic migraines, requiring urgent neurological consultation for further assessment and treatment plans.']\n","spaCy Words: ['The', 'patient', 'presented', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'requiring', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plans', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"342518fc","executionInfo":{"status":"ok","timestamp":1767867487974,"user_tz":-330,"elapsed":56,"user":{"displayName":"DANGETI KARTHIK RAM","userId":"02974783247328024150"}},"outputId":"a1b948c4-87ec-46bc-81af-a1a917e026ac"},"source":["print(\"\\n--- Comparison of Tokenization Results ---\")\n","print(\"NLTK Sentences (Count):\", len(nltk_sentences))\n","print(\"spaCy Sentences (Count):\", len(spacy_sentences))\n","print(\"NLTK Words (Count):\", len(nltk_words))\n","print(\"spaCy Words (Count):\", len(spacy_words))\n","\n","# Check if the tokenizations are identical for this specific text\n","if nltk_sentences == spacy_sentences and nltk_words == spacy_words:\n","    print(\"\\nFor this particular medical text, NLTK and spaCy produced identical sentence and word tokenizations.\")\n","else:\n","    print(\"\\nDifferences observed in tokenization between NLTK and spaCy.\")"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Comparison of Tokenization Results ---\n","NLTK Sentences (Count): 1\n","spaCy Sentences (Count): 1\n","NLTK Words (Count): 24\n","spaCy Words (Count): 24\n","\n","For this particular medical text, NLTK and spaCy produced identical sentence and word tokenizations.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8a514b8","executionInfo":{"status":"ok","timestamp":1767867510343,"user_tz":-330,"elapsed":45,"user":{"displayName":"DANGETI KARTHIK RAM","userId":"02974783247328024150"}},"outputId":"c9f6df9b-88db-446a-e71f-b7fdf592356c"},"source":["stemmer = PorterStemmer()\n","nltk_stemmed_words = [stemmer.stem(word) for word in nltk_words]\n","\n","print(\"\\n--- NLTK Porter Stemming ---\")\n","print(\"Original NLTK Words:\", nltk_words)\n","print(\"Stemmed NLTK Words:\", nltk_stemmed_words)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- NLTK Porter Stemming ---\n","Original NLTK Words: ['The', 'patient', 'presented', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'requiring', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plans', '.']\n","Stemmed NLTK Words: ['the', 'patient', 'present', 'with', 'persist', 'headach', 'and', 'a', 'histori', 'of', 'chronic', 'migrain', ',', 'requir', 'urgent', 'neurolog', 'consult', 'for', 'further', 'assess', 'and', 'treatment', 'plan', '.']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f979594b","executionInfo":{"status":"ok","timestamp":1767867531467,"user_tz":-330,"elapsed":5029,"user":{"displayName":"DANGETI KARTHIK RAM","userId":"02974783247328024150"}},"outputId":"7417ec78-c249-4eac-d249-a5edd0e46734"},"source":["lemmatizer = WordNetLemmatizer()\n","nltk_lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in nltk_words]\n","spacy_lemmatized_words = [token.lemma_ for token in doc]\n","\n","print(\"\\n--- NLTK Lemmatization ---\")\n","print(\"Original NLTK Words:\", nltk_words)\n","print(\"NLTK Lemmatized Words:\", nltk_lemmatized_words)\n","\n","print(\"\\n--- spaCy Lemmatization ---\")\n","print(\"Original spaCy Words:\", spacy_words)\n","print(\"spaCy Lemmatized Words:\", spacy_lemmatized_words)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- NLTK Lemmatization ---\n","Original NLTK Words: ['The', 'patient', 'presented', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'requiring', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plans', '.']\n","NLTK Lemmatized Words: ['The', 'patient', 'present', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'require', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plan', '.']\n","\n","--- spaCy Lemmatization ---\n","Original spaCy Words: ['The', 'patient', 'presented', 'with', 'persistent', 'headaches', 'and', 'a', 'history', 'of', 'chronic', 'migraines', ',', 'requiring', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plans', '.']\n","spaCy Lemmatized Words: ['the', 'patient', 'present', 'with', 'persistent', 'headache', 'and', 'a', 'history', 'of', 'chronic', 'migraine', ',', 'require', 'urgent', 'neurological', 'consultation', 'for', 'further', 'assessment', 'and', 'treatment', 'plan', '.']\n"]}]}]}