{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1slhTJqE1Il9Y_Ril5p1ctGs9yPAlHw1Q","timestamp":1768884298827},{"file_id":"1vpDMsiXnq9GiyeMbnOu0enrJyLWeg1hz","timestamp":1768884105930}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Aim: Understand POS tagging challenges in informal, noisy text."],"metadata":{"id":"RMzxqmu_gZBq"}},{"cell_type":"markdown","source":["step 1 : install and import librabries"],"metadata":{"id":"YiIvruzff5ZL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0maPqKechm-","executionInfo":{"status":"ok","timestamp":1768278717496,"user_tz":-330,"elapsed":4720,"user":{"displayName":"ALURI BHAVANEESH","userId":"12608802935542722588"}},"outputId":"440709c6-8fdc-48dd-b911-c3a8f714b9d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"]}],"source":["!pip install nltk\n","import nltk\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import twitter_samples"]},{"cell_type":"markdown","source":["step 2 : Download required nltk resourses"],"metadata":{"id":"5wZQiMQdgEdG"}},{"cell_type":"code","source":["nltk.download('twitter_samples')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger_eng')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_uuojQqfnio","executionInfo":{"status":"ok","timestamp":1768278717597,"user_tz":-330,"elapsed":98,"user":{"displayName":"ALURI BHAVANEESH","userId":"12608802935542722588"}},"outputId":"ce96fe08-6798-40f4-ccc2-21deed48626a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n","[nltk_data]   Package twitter_samples is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Step - 3 :Load Tweets Dataset"],"metadata":{"id":"8w_W53Iuh8ls"}},{"cell_type":"code","source":["tweets = twitter_samples.strings('positive_tweets.json')\n","\n","for i in range(3):\n","  print(\"Tweet\",i+1)\n","  print(tweets[i])\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBw8tHZAiDDh","executionInfo":{"status":"ok","timestamp":1768278718449,"user_tz":-330,"elapsed":850,"user":{"displayName":"ALURI BHAVANEESH","userId":"12608802935542722588"}},"outputId":"4fb96132-ee79-4b9e-f565-0d37bc46974b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tweet 1\n","#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n","\n","Tweet 2\n","@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!\n","\n","Tweet 3\n","@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!\n","\n"]}]},{"cell_type":"markdown","source":["step - 4 : Tokenization and Tweet Tokenizer"],"metadata":{"id":"LwkWEMTjjRQF"}},{"cell_type":"code","source":["tokenizer = TweetTokenizer(\n","    preserve_case=False,\n","    strip_handles=True,\n","    reduce_len=True\n",")\n","\n","tokenized_tweets = [tokenizer.tokenize(tweet) for tweet in tweets[:3]]\n","\n","for i, tokens in enumerate(tokenized_tweets):\n","    print(f\"Original Tweet {i+1}:\")\n","\n","    print(tweets[i])\n","\n","    print(f\"Tokenized Tweet {i+1} (processed with advanced tokenizer):\")\n","\n","    print(tokens)\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HHsOYuzJodNK","executionInfo":{"status":"ok","timestamp":1768279536501,"user_tz":-330,"elapsed":15,"user":{"displayName":"ALURI BHAVANEESH","userId":"12608802935542722588"}},"outputId":"f490961f-045a-4511-f11d-fc0ea8964a47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Tweet 1:\n","#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n","Tokenized Tweet 1 (processed with advanced tokenizer):\n","['#followfriday', 'for', 'being', 'top', 'engaged', 'members', 'in', 'my', 'community', 'this', 'week', ':)']\n","\n","Original Tweet 2:\n","@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!\n","Tokenized Tweet 2 (processed with advanced tokenizer):\n","['hey', 'james', '!', 'how', 'odd', ':/', 'please', 'call', 'our', 'contact', 'centre', 'on', '02392441234', 'and', 'we', 'will', 'be', 'able', 'to', 'assist', 'you', ':)', 'many', 'thanks', '!']\n","\n","Original Tweet 3:\n","@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!\n","Tokenized Tweet 3 (processed with advanced tokenizer):\n","['we', 'had', 'a', 'listen', 'last', 'night', ':)', 'as', 'you', 'bleed', 'is', 'an', 'amazing', 'track', '.', 'when', 'are', 'you', 'in', 'scotland', '?', '!']\n","\n"]}]},{"cell_type":"markdown","source":["step 5 : POS tagging using NLTK"],"metadata":{"id":"H3JHXHE9p8YK"}},{"cell_type":"code","source":["text = \"Akhil bhAAi üòç is playing with bunty üêª \"\n","\n","tokenized_text = tokenization.tokenize(text)\n","\n","tagset = nltk.pos_tag(tokenized_text)\n","\n","print(\"original text: \",text)\n","print(\"Tokenaized text: \",tokenized_text)\n","print(\"Pos tags: \",tagset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbJeZxRgke2f","executionInfo":{"status":"ok","timestamp":1768278718517,"user_tz":-330,"elapsed":12,"user":{"displayName":"ALURI BHAVANEESH","userId":"12608802935542722588"}},"outputId":"2a709dd7-c095-4f71-a02d-749234a03dd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["original text:  Akhil bhAAi üòç is playing with bunty üêª \n","Tokenaized text:  ['Akhil', 'bhAAi', 'üòç', 'is', 'playing', 'with', 'bunty', 'üêª']\n","Pos tags:  [('Akhil', 'NNP'), ('bhAAi', 'NN'), ('üòç', 'NN'), ('is', 'VBZ'), ('playing', 'VBG'), ('with', 'IN'), ('bunty', 'NN'), ('üêª', 'NN')]\n"]}]},{"cell_type":"markdown","source":["Step - 6 : Extract nouns and verbs"],"metadata":{"id":"WjqUpU_HnAhT"}},{"cell_type":"code","source":["nouns = []\n","verbs = []\n","\n","for word, tag in tagset:\n","  if tag.startswith('NN'):\n","    nouns.append(word)\n","  elif tag.startswith('VB'):\n","    verbs.append(word)\n","\n","print(\"Nouns: \",nouns)\n","print(\"Verbs: \",verbs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcRDfcMamg4H","executionInfo":{"status":"ok","timestamp":1768279644475,"user_tz":-330,"elapsed":31,"user":{"displayName":"ALURI BHAVANEESH","userId":"12608802935542722588"}},"outputId":"d2c54be8-395e-4896-e4ae-ae1787fce56f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nouns:  ['Akhil', 'bhAAi', 'üòç', 'bunty', 'üêª']\n","Verbs:  ['is', 'playing']\n"]}]}]}